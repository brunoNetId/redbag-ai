{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20a0971",
   "metadata": {
    "id": "e20a0971"
   },
   "source": [
    "# Building an Image Classifier Deep Network applying Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8wM31kI5-PeJ",
   "metadata": {
    "id": "8wM31kI5-PeJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import tf.keras.utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad8bd9",
   "metadata": {
    "id": "42ad8bd9"
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f9b25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d58f9b25",
    "outputId": "e8fb47f7-64a8-4912-81cb-3f4f6bc2deec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset's directory path\n",
    "directory = \"../dataset/images/\"\n",
    "\n",
    "batch_size = 32\n",
    "image_size = (160,160) # resize the images to 160x160\n",
    "\n",
    "# create training and validation sets\n",
    "# use image_dataset_from_directory to load the images\n",
    "# set a validation split and specify the subset ('training' or 'validation')\n",
    "# set the random seeds to match eachother (to avoid overlapping of the images in\n",
    "# train and validation sets)\n",
    "\n",
    "train_set = tf.keras.utils.image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=image_size,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='training',\n",
    "                                             seed=42)\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=image_size,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='validation',\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e4364d-4e79-4f34-ad2b-7a66447040ea",
   "metadata": {},
   "source": [
    "# Obtain Class names (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Af79dbaPaA6Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Af79dbaPaA6Z",
    "outputId": "c123d6d9-e133-4b73-819d-9d8e9e3ecc33",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print some images\n",
    "# use .class_names attribute to retrieve the classes of the images from the dicrectories names\n",
    "class_names = train_set.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924302d9-d2af-47ba-90b4-c80d55519f24",
   "metadata": {},
   "source": [
    "# Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dba746",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "26dba746",
    "outputId": "f8b411f0-7c07-459d-d185-0bb6447e696c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_set.take(1): # take 1 batch randomly\n",
    "    for i in range(9): # print 9 images of that batch\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58fc24",
   "metadata": {
    "id": "eb58fc24",
    "tags": []
   },
   "source": [
    "# Import pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b14a7c",
   "metadata": {
    "id": "e4b14a7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# explore the MobileNetV2 network\n",
    "image_shape = image_size + (3,)\n",
    "pre_trained_model = tf.keras.applications.MobileNetV2(input_shape=image_shape,\n",
    "                                               include_top=True,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kpZ_HjyCgQM_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpZ_HjyCgQM_",
    "outputId": "1fc944f2-ccef-4288-cddb-dc50c6ce3ce4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pre_trained_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717277b5",
   "metadata": {
    "id": "717277b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the pre-trained model without the final layers\n",
    "image_shape = image_size + (3,)\n",
    "pre_trained_model = tf.keras.applications.MobileNetV2(input_shape=image_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbb801-a26f-49e5-82af-f90abbed99f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pre_trained_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fae286",
   "metadata": {
    "id": "47fae286",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize the inputs to the range [-1, 1]\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "# freeze the base model by making it non trainable\n",
    "pre_trained_model.trainable = False\n",
    "# define the input layer\n",
    "inputs = tf.keras.Input(shape=image_shape) \n",
    "# preprocess the inputs\n",
    "x = preprocess_input(inputs)\n",
    "# add the pre-trained (not trainable) model\n",
    "x = pre_trained_model(x, training=False)\n",
    "# add a pooling layer\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# add a dropout layer for regularization\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# add the output layer\n",
    "# outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation='sigmoid')(x)\n",
    "# define the model with its inputs and outputs\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38593a1f-30d5-4c52-937e-8163e2c1ee62",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eba7cf",
   "metadata": {
    "id": "86eba7cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              # loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d413de-1799-47b0-b32c-6d50af6b3196",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b8928",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac9b8928",
    "outputId": "0098c3b3-219a-4ecb-b4a0-205707224572",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = model.fit(train_set, validation_data=validation_set, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a2c74-499c-4361-8d71-8639f8db7222",
   "metadata": {},
   "source": [
    "# Plot Loss/Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HyGOyZB8rJoK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "HyGOyZB8rJoK",
    "outputId": "631be67a-8609-4c2c-a5c8-3551b140ca2d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = [0.] + history.history['accuracy']\n",
    "val_acc = [0.] + history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training')\n",
    "plt.plot(val_acc, label='Validation')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training')\n",
    "plt.plot(val_loss, label='Validation')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d073e25-75ad-4fdd-b55c-c38e451444be",
   "metadata": {},
   "source": [
    "# Verify prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50688d81-da7e-4fe2-82b3-691e66846fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict images\n",
    "test_path = \"../dataset/images/tea-green\"\n",
    "test_imgs = os.listdir(test_path)\n",
    "\n",
    "ti = len(test_imgs)\n",
    "print(\"number of images: \", ti)\n",
    "\n",
    "data = np.empty((ti, 160, 160, 3))\n",
    "\n",
    "for i in test_imgs:\n",
    "    try:\n",
    "        image_path = os.path.join(test_path, i)\n",
    "        # print(image_path)\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = img.resize((160, 160), Image.LANCZOS)\n",
    "        # img = img.resize((160, 160), Image.ANTIALIAS)\n",
    "        img = np.asarray(img)\n",
    "        # img = preprocess_input(img)\n",
    "        # print(test_imgs.index(i))\n",
    "        data[test_imgs.index(i)] = img\n",
    "    except IsADirectoryError:\n",
    "        print(\"bypassing: \"+image_path)\n",
    "        continue\n",
    "\n",
    "predictions = model.predict(data)\n",
    "\n",
    "# print(predictions)\n",
    "print(np.argmax(predictions, axis=1))\n",
    "print(\"Above, should be all 1's.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d610fd-745c-42b8-8619-fcfe87bd6e75",
   "metadata": {},
   "source": [
    "# Verify prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb8f68-457e-4839-96c6-ea04939b493b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict images\n",
    "test_path = \"../dataset/images/other\"\n",
    "test_imgs = os.listdir(test_path)\n",
    "\n",
    "\n",
    "ti = len(test_imgs)\n",
    "print(\"number of images: \", ti)\n",
    "\n",
    "data = np.empty((ti, 160, 160, 3))\n",
    "\n",
    "for i in test_imgs:\n",
    "    image_path = os.path.join(test_path, i)\n",
    "    # print(image_path)\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((160, 160), Image.LANCZOS)\n",
    "    # img = img.resize((160, 160), Image.ANTIALIAS)\n",
    "    img = np.asarray(img)\n",
    "    # img = preprocess_input(img)\n",
    "    # print(test_imgs.index(i))\n",
    "    data[test_imgs.index(i)] = img\n",
    "\n",
    "\n",
    "predictions = model.predict(data)\n",
    "\n",
    "# print(predictions)\n",
    "\n",
    "print(np.argmax(predictions, axis=1))\n",
    "print(\"Above, should be all 0's.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b87367",
   "metadata": {
    "id": "12b87367"
   },
   "source": [
    "# With Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713011b6",
   "metadata": {
    "id": "713011b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# freeze the base model by making it non trainable\n",
    "pre_trained_model.trainable = False\n",
    "# define the input layer\n",
    "inputs = tf.keras.Input(shape=image_shape) \n",
    "# apply data augmentation\n",
    "x = tf.keras.Sequential([tf.keras.layers.RandomFlip('horizontal'),\n",
    "                         tf.keras.layers.RandomRotation(0.2)])(inputs)\n",
    "\n",
    "# preprocess the augmented inputs\n",
    "x = preprocess_input(x)\n",
    "# add the pre-trained (not trainable) model\n",
    "x = pre_trained_model(x, training=False)\n",
    "# add a pooling layer\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# add a dropout layer for regularization\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# add the output layer\n",
    "# outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation='sigmoid')(x)\n",
    "# define the model with its inputs and outputs\n",
    "model_augmented = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c62c8e",
   "metadata": {
    "id": "03c62c8e",
    "outputId": "19df7dc7-c3bc-4565-9ea0-6fcb2cb92c20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_augmented.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8cbc86-ecb2-4d86-849d-a93eaff13c50",
   "metadata": {},
   "source": [
    "# Compile augmented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb7e19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbcb7e19",
    "outputId": "63ca846a-0374-4f41-ddb1-da02aa329c47",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "base_learning_rate = 0.001\n",
    "model_augmented.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              # loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# train the model\n",
    "history_augmented = model_augmented.fit(train_set, validation_data=validation_set, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd34f3-911a-470a-bd71-db1b53838bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict images\n",
    "test_path = \"../dataset/images/tea-green\"\n",
    "test_imgs = os.listdir(test_path)\n",
    "\n",
    "\n",
    "ti = len(test_imgs)\n",
    "print(\"number of images: \", ti)\n",
    "\n",
    "data = np.empty((ti, 160, 160, 3))\n",
    "\n",
    "for i in test_imgs:\n",
    "    try:\n",
    "        image_path = os.path.join(test_path, i)\n",
    "        # print(image_path)\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = img.resize((160, 160), Image.LANCZOS)\n",
    "        # img = img.resize((160, 160), Image.ANTIALIAS)\n",
    "        img = np.asarray(img)\n",
    "        # img = preprocess_input(img)\n",
    "        # print(test_imgs.index(i))\n",
    "        data[test_imgs.index(i)] = img\n",
    "    except IsADirectoryError:\n",
    "        print(\"bypassing: \"+image_path)\n",
    "        continue\n",
    "\n",
    "predictions = model_augmented.predict(data)\n",
    "\n",
    "# print(predictions)\n",
    "print(np.argmax(predictions, axis=1))\n",
    "print(\"Above, should be all 1's.\")\n",
    "print(\"Results should have improved after augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a42f2-1279-4756-9b3b-9ff54b17e880",
   "metadata": {},
   "source": [
    "# test single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ca52d-1a0b-482c-acdb-7c58ce90742b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testfile = \"samples/bali-tea.jpeg\"\n",
    "\n",
    "img = Image.open(testfile).convert('RGB')\n",
    "img = img.resize((160, 160), Image.LANCZOS)\n",
    "img = np.asarray(img)\n",
    "# print(img)\n",
    "\n",
    "mydata = np.empty((1, 160, 160, 3))\n",
    "mydata[0] = img\n",
    "\n",
    "# print(mydata)\n",
    "\n",
    "mypredition = model_augmented.predict(mydata)\n",
    "\n",
    "print(mypredition)\n",
    "print(np.argmax(mypredition, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3949cce-82f0-461b-b835-c79cb6672ac7",
   "metadata": {},
   "source": [
    "# Save augmented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eacffa-4f28-4830-b135-4ccef36487d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(model_augmented, \"./models/base/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b57d45-dd5e-4a87-a586-df776b297901",
   "metadata": {},
   "source": [
    "# Infer saved augmented model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7273a4-257e-44d8-9de1-adf63bd75741",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60760e67-e7ee-46fb-a8fd-817350199881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smodel = tf.saved_model.load(\"./models/base/2\")\n",
    "# smodel = tf.keras.models.load_model('saved_model/tea_model')\n",
    "\n",
    "# smodel = tf.saved_model.load(\"saved_model/tea_model_b64\")\n",
    "# This is the current signature, that only accepts image tensors as input\n",
    "signature = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0040293-ff70-4743-a4b4-152b16d32055",
   "metadata": {},
   "source": [
    "### Obtain In/Out keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf5552-b188-4196-a026-8d1b165f41c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get inputs, and find the second one (first one is empty)\n",
    "iterInputs = iter(signature.structured_input_signature)\n",
    "signIn = next(iterInputs)\n",
    "signIn = next(iterInputs)\n",
    "\n",
    "# get the key\n",
    "keyIn = list(signIn.keys())[0]\n",
    "print(keyIn)\n",
    "\n",
    "# obtain the key name of the output (typically 'dense_X')\n",
    "keyOut = next(iter(signature.structured_outputs))\n",
    "print(keyOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d3fcc-5d47-465d-a896-49a2560ff8d9",
   "metadata": {},
   "source": [
    "### Load image and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32818097-0bae-453d-bf01-82c503f969c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testfile = \"samples/bali-tea.jpeg\"\n",
    "\n",
    "# load test image\n",
    "content = tf.io.read_file(testfile)\n",
    "image = tf.image.decode_jpeg(content,channels=3)\n",
    "\n",
    "# resize image\n",
    "image = tf.image.resize(image, [160, 160])\n",
    "\n",
    "# expand dimension to match signature\n",
    "image = tf.expand_dims(image, 0)\n",
    "\n",
    "# get predictor function\n",
    "f = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "# prepare predictor arguments\n",
    "kwargs = {keyIn: image}\n",
    "\n",
    "# predict\n",
    "myprediction = f(**kwargs)\n",
    "\n",
    "print(myprediction)\n",
    "print(\"predicted class: \", np.argmax(myprediction[keyOut],axis=1))\n",
    "\n",
    "# print(type(tf.argmax(myprediction[keyOut])))\n",
    "\n",
    "# # print(tf.argmax(myprediction,axis=1))\n",
    "# print(tf.argmax(myprediction[keyOut],axis=1))\n",
    "\n",
    "# print(mypredition)\n",
    "# print(tf.argmax(myprediction[keyOut], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801da411-d7f2-4394-93e2-cb4e97802a69",
   "metadata": {},
   "source": [
    "# Save model with Base64 Signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec77e99-4c19-4c51-8bc9-7f9ddd08bff9",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac7404-0aa1-4e61-928c-efee862219a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(class_names)\n",
    "labels = tf.constant([class_names])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3219248-d436-42af-a996-387fd5bb1f83",
   "metadata": {},
   "source": [
    "### Load augmented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d1e9a-3735-4578-8df8-8896781e3b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smodel = tf.saved_model.load(\"./models/base/2\")\n",
    "\n",
    "# This is the current signature, that only accepts image tensors as input\n",
    "signature = smodel.signatures[\"serving_default\"]\n",
    "print(signature)\n",
    "\n",
    "# obtain the key name of the output (typically 'dense_X')\n",
    "keyOutput = next(iter(signature.structured_outputs))\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def my_predict(image_b64):\n",
    "\n",
    "    # get content\n",
    "    content = image_b64[0]\n",
    "\n",
    "    # decode image    \n",
    "    image = tf.image.decode_jpeg(content,channels=3)\n",
    "    # tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "    # resize image\n",
    "    image = tf.image.resize(image, [160, 160])\n",
    "\n",
    "    # expand dimension to match signature\n",
    "    image = tf.expand_dims(image, 0)\n",
    "\n",
    "    # execute prediction\n",
    "    prediction = signature(image)\n",
    "\n",
    "    # obtain index of maximum probability prediction\n",
    "    idx = tf.argmax(prediction[keyOutput],axis=1)\n",
    "\n",
    "    # obtain the label for given index\n",
    "    label = tf.gather(labels, idx, batch_dims=1)\n",
    "\n",
    "    # obtain probability from Tensor\n",
    "    probability = prediction[keyOutput][0,idx[0]]\n",
    "\n",
    "    # combine result in String Tensor format with [label,probability]\n",
    "    result = tf.concat([label, [tf.as_string(probability)]], axis=0)\n",
    "\n",
    "    # return result_tensor\n",
    "    return result\n",
    "\n",
    "\n",
    "# Create new signature, to read b64 images\n",
    "new_signature = my_predict.get_concrete_function(\n",
    "    image_b64=tf.TensorSpec(name=\"image_b64\", shape=[1], dtype=tf.string)\n",
    ")\n",
    "\n",
    "# Save model with Base64 input signature\n",
    "tf.saved_model.save(\n",
    "    smodel,\n",
    "    export_dir=\"./models/redbag/2\",\n",
    "    signatures=new_signature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f2fac-5d8e-40f6-a8cc-b53671c1e978",
   "metadata": {},
   "source": [
    "# Test Base64 Model with single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a9b5d9-3bfc-48e6-b13a-efd0df2a1040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smodel = tf.saved_model.load(\"./models/redbag/2\")\n",
    "\n",
    "# Load model's signature\n",
    "signature = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbc0d5-70d9-4156-a6da-969a70a14aa4",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e34858-5b74-4528-b631-9c66d8cfef58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testfile = \"samples/bali-tea.jpeg\"\n",
    "\n",
    "# load test image\n",
    "content = tf.io.read_file(testfile)\n",
    "\n",
    "# reshape to signature's expected dimensions\n",
    "content = tf.reshape(content, shape = [1])\n",
    "\n",
    "# obtain signature\n",
    "f = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "# run prediction\n",
    "myprediction = f(image_b64=content)\n",
    "print(myprediction)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Alpaca image classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
